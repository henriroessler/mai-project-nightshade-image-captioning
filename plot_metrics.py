import argparse
import os

from matplotlib import pyplot as plt
import matplotlib as mpl
import pandas as pd

# Colormap
CMAP = mpl.colormaps['tab20']

# Colors for each concept and concept pair type (intra, inter)
# (this ensures consistent colors across multiple visualizations)
COLORS = {
    'orange': CMAP(0.6),
    'banana': CMAP(0.6),
    'horse': CMAP(0.4),
    'cow': CMAP(0.4),
    'cup': CMAP(0.1),
    'bottle': CMAP(0.1),
    'skateboard': CMAP(0.5),
    'surfboard': CMAP(0.5),
    'car': CMAP(0.8),
    'motorcycle': CMAP(0.8),
    'person': CMAP(0.2),
    'airplane': CMAP(0.2),
    'boat': CMAP(0.3),
    'sandwich': CMAP(0.3),
    'cat': CMAP(0.0),
    'train': CMAP(0.0),
    'wine glass': CMAP(0.7),
    'traffic light': CMAP(0.7),
    'sink': CMAP(0.9),
    'backpack': CMAP(0.9),
    'inter': CMAP(0.0),
    'intra': CMAP(0.1)
}

def parse_args():
    """
    Parse program arguments

    :return: Program arguments
    """

    parser = argparse.ArgumentParser()

    parser.add_argument(
        '--file',
        help='CSV file generated by the eval.py script.'
    )
    parser.add_argument(
        '--plot-dir',
        help='Directory where the plot shall be saved to.'
    )
    parser.add_argument(
        '--concept-pairs-file',
        help='Path to file containing concept pairs.'
    )
    parser.add_argument(
        '--group-by', default='target_concept',
        help='Column by which the results shall be grouped by.'
    )
    parser.add_argument(
        '--filter', nargs='+', required=False, default=None,
        help='Filter to plot specific groups only. If not specified, all groups are plotted.'
    )
    parser.add_argument(
        '--legend-offset', type=float, default=1.13,
        help='X offset of legend.'
    )
    parser.add_argument(
        '--legend-auto', action='store_true',
        help='Whether the legend shall be placed automatically or in the center right.'
    )

    return parser.parse_args()


def plot_metric(args, metric: str, ylabel: str, ylim = (None, None)):
    """
    Plot the specified metric (Y) against the fraction of poisoned images used for finetuning (X).

    :param args: Program arguments
    :param metric: Metric to plot
    :param ylabel: Y label
    :param ylim: Y limits
    """

    # Set linewidth
    plt.rc("lines", linewidth=2)

    # Read concept pairs
    concept_pairs_df = pd.read_csv(args.concept_pairs_file)

    # Read metrics
    df = pd.read_csv(args.file)

    # Add concept pair type (inter, intra), target concept and finetuning strategy (uni- or bidirectional)
    df = df.merge(concept_pairs_df[['model', 'target_concept', 'type']], on='target_concept')

    # Calculate attack success rates (for detailed explanations, refer to main() function)
    df['asr'] = (df['attack_original'] + df['attack_both']) / df['pretrained_target'] * 100.0
    df['asr2'] = (df['finetuned_original'] + df['finetuned_both']) / df['num_images'] * 100.0

    # For each finetuning strategy (uni- or bidirectional), create a separate plot
    sup_groups = df.groupby('finetune_type')
    for finetune_type, sup_df in sup_groups:

        # For each posioning direction (X -> Y = origpairs, Y -> X = switchpairs), create a separate plot
        for model in ('origpairs', 'switchpairs'):
            if finetune_type == 'origpairs':
                # For unidirectional poisoning, we only want to plot the results of the current direction.
                # This is skipped for bidirectional poisoning, because we then want to include both directions in our
                # plot. E.g., when we plot metrics for intra- and inter-class concept pairs for bidirectionally
                # finetuned models, each line shall represent the average over both X -> Y and Y -> X concept pairs in
                # the corresponding (intra/inter) class.
                sup_df = sup_df[sup_df['model'] == model]

            # Add pretrained results. This step is needed as the results for the pretrained ClipCap model are not
            # annotated with a specific finetuning strategy.
            if finetune_type == 'origpairs':
                # For unidirectional poisoning, only include pretrained results of the current direction
                sup_df = pd.concat([sup_df, df[(df['frac'] == 0) & (df['model'] == model)]], ignore_index=True)
            else:
                # For bidirectional poisoning, include both directions
                sup_df = pd.concat([sup_df, df[df['frac'] == 0]], ignore_index=True)

            # Create figure and set X and Y label
            fig, ax = plt.subplots(figsize=(6, 3))
            ax.set_ylabel(ylabel)
            ax.set_xlabel('Fraction of poisoned images [%]')

            # If specified, include results for specific groups only
            if args.filter is not None:
                sup_df = sup_df[sup_df[args.group_by].isin(args.filter)]

            # Group the relevant results and iterate over each group
            for group_by_key, sub_df in sup_df.groupby(args.group_by):
                # Calculate the average metric for each poisoning fraction
                aggregated_df = sub_df.groupby('frac').mean(numeric_only=True).sort_index()

                # Get x any y values
                x = aggregated_df.index
                y = aggregated_df[metric]

                # Plot values
                marker = 'o-'
                ax.plot(x, y, marker, color=COLORS.get(group_by_key), label=group_by_key)

            # Set plot parameters
            ax.set_ylim(*ylim)
            ax.set_xticks(labels=['0', '5', '10', '25', '50', '100'], ticks=[0, 5, 10, 25, 50, 100])
            ax.tick_params(direction='in')
            legend_kwargs = dict(fancybox=True, ncol=1, loc='best')
            if not args.legend_auto:
                legend_kwargs.update({'loc': 'right', 'bbox_to_anchor': (args.legend_offset, 0.5)})
            ax.legend(**legend_kwargs)

            # Save plot
            filename = f'{metric}_{model}_{finetune_type}_{args.group_by}'
            if args.filter is not None:
                filename += f'_{"_".join(args.filter)}'
            path = os.path.join(args.plot_dir, f'{filename}.png')
            fig.savefig(path, bbox_inches='tight', dpi=200)


def main():
    """
    Main program.
    """

    # Parse program arguments
    args = parse_args()

    # Plot BLEU scores
    plot_metric(args, 'finetuned_bleu', 'BLEU score', (0.0, 0.4))

    # Plot attack success rate (not used in publication)
    # This attack success rate is defined as the fraction of test images that contained the original (wrong) concept out
    # of all test images that the pretrained ClipCap model generated a caption with the target (correct) concept for.
    plot_metric(args, 'asr', 'Attack success rate [%]', (-5, 105))

    # Plot attack success rate (used in publication)
    # As opposed to the attack success rate above, here we simply calculate the fraction of all test images that got the
    # original (wrong) concept in the caption, no matter what the pretrained ClipCap model predicted.
    plot_metric(args, 'asr2', 'Attack success rate [%]', (-5, 105))


if __name__ == '__main__':
    main()
